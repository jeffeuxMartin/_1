# Reference of NLP tasks using different meta-learning methods.

||(A) Learning to initialize|(B) Learning to compare|(C) Other|
|--- |--- |--- |--- |
|Text Classification|[Dou et al., EMNLP’19](#Dou__COMMA__EMNLP19) <br /> [Bansal et al., arXiv’19](#Bansal__COMMA__arXiv19) <br /> [Nithin et al., Findings of EMNLP’20](#holla-etal-2020-learning) <br /> [Zhou et al., arXiv’21](#MetaKD-arXiv21) <br /> [Niels et al., EACL’21](#van-der-heijden-etal-2021-multilingual) <br /> [Trapit et al., EMNLP’20](#bansal-etal-2020-self) <br /> [Shikhar et al., NAACL’21](#murty-etal-2021-dreca)|[Yu et al., ACL’18](#Yu__COMMA__ACL18) <br /> [Tan et al., EMNLP’19](#Tan__COMMA__EMNLP19) <br /> [Geng et al., EMNLP’19](#Geng__COMMA__EMNLP19) <br /> [Sun et al., EMNLP’19](#Sun__COMMA__EMNLP19) <br /> [Ruiying et al., ACL’20](#geng2020dynamic)|Learning the learning algorithm: <br /> [Wu et al., EMNLP’19](#Wu__COMMA__EMNLP19) <br /> Network architecture search: <br /> [Ramakanth et al., EMNLP’20](#pasunuru2020fenas) <br /> [Ramakanth et al., ACL’19](#pasunuru2019continual) <br /> Learning to optimize: <br /> [Xu et al., Proceedings of the First Workshop on Meta Learning and Its Applications to Natural Language Processing’21](#learningToOptimize__COMMA__metaNLP21) <br /> Learning to select data: <br /> [Zheng et al., AAAI’21](#label-correction-aaai21)|
|Sequence Labelng|[Wu et al., AAAI’20](#Wu__COMMA__AAAI20) <br /> [Mengzhou et al., NAACL’21](#xia-etal-2021-metaxl)|[Hou et al., ACL’20](#Hou__COMMA__ACL20) <br /> [Yi et al., EMNLP’20](#yang2020frustratingly) <br /> [Cennet et al., EACL’21](#oguz2021few)|Network architecture search: <br /> [Yinqiao et al., ACL’20](#li2020learning) <br /> [Yufan et al., EMNLP’19](#jiang2019improved)|
|Relation Classification|[Obamuyide et al., ACL’19](#Obamuyide__COMMA__ACL19) <br /> [Bose et al., arXiv’19](#Bose__COMMA__arXiv19) <br /> [Lv et al., EMNLP’19](#Lv__COMMA__EMNLP19)|[Ye et al., ACL’19](#Ye__COMMA__ACL19) <br /> [Chen et al., EMNLP’19](#Chen__COMMA__EMNLP19) <br /> [Xiong et al., EMNLP’18](#Xiong__COMMA__EMNLP18) <br /> [Gao et al., AAAI’19](#Gao__COMMA__AAAI19) <br /> [Haopeng et al., Proceedings of the 28th International Conference on Computational Linguistics’20](#ren2020two)||
|Knowledge Graph Completion||[Wenhan et al., EMNLP’18](#xiong2018one) <br /> [Zihao et al., EMNLP-IJCNLP’19](#wang2019tackling) <br /> [Chuxu et al., AAAI’20](#zhang2020few) <br /> [Jiawei et al., EMNLP’20](#sheng2020adaptive)||
|Word Embedding|[Hu et al., ACL’19](#Hu__COMMA__ACL19)|[Sun et al., EMNLP’18](#Sun__COMMA__EMNLP18)|Network architecture search: <br /> [Yinqiao et al., ACL’20](#li2020learning) <br /> [Yufan et al., EMNLP’19](#jiang2019improved)|
|Question Answering|[Meryem et al., NAACL’21](#mhamdi-etal-2021-x) <br /> [Farhad et al., EMNLP’20](#nooralahzadeh-etal-2020-zero) <br /> [Ming et al., ACL’20](#yan-etal-2020-multi-source) <br /> [Yuncheng et al., EMNLP’20](#hua-etal-2020-shot)|||
|Machine Translation|[Gu et al., EMNLP’18](#Gu__COMMA__EMNLP18) <br /> [Indurthi et al., ICASSP’20](#Indurthi__COMMA__arXiv19) <br /> [Rumeng et al., AAAI’20](#Li_Wang_Yu_2020) <br /> [Park et al., ACL’21](#unsupervisedMT-acl21)||Network architecture search: <br /> [Hanrui et al., ACL’20](#wang2020hat) <br /> Learning to select data: <br /> [Xinyi et al., ACL’20](#wang2020balancing) <br /> [Hieu et al., ICLR’21](#pham2020meta)|
|Parsing|[Guo et al., ACL’19](#Guo__COMMA__ACL19) <br /> [Huang et al., NAACL’18](#Huang__COMMA__NAACL18) <br /> [Langedijk et al., arXiv’21](#multiparsing) <br /> [Xilun et al., EMNLP’20](#chen-etal-2020-low) <br /> [Bailin et al., NAACL’21](#wang-etal-2021-meta)|||
|Dialogue|[Qian et al., ACL’19](#Qian__COMMA__ACL19) <br /> [Madotto et al., ACL’19](#Madotto__COMMA__ACL19) <br /> [Mi et al., IJCAI’19](#Mi__COMMA__IJCAI19) <br /> [Huang et al., ACL’20](#Huang__COMMA__ACL20) <br /> [Saket et al., EACL’21](#dingliwal-etal-2021-shot) <br /> [Qian et al., AAAI’21](#ST-dialogue-AAAI21) <br /> [Yinpei et al., ACL’20](#dai-etal-2020-learning) <br /> [Yi et al., Findings of EMNLP’20](#huang-etal-2020-towards-low)||Learning to optimize: <br /> [Chien et al., INTERSPEECH’19](#Chien__COMMA__INTERSPEECH19)|
|||||
|Speech Recognition|[Hsu et al., ICASSP’20](#Hsu__COMMA__ICASSP20) <br /> [Klejch et al., ASRU’19](#Klejch__COMMA__ASRU19) <br /> [Winata et al., ACL’20](#Winata__COMMA__ACL2020) <br /> [Winata et al., INTERSPEECH’20](#Winata__COMMA__INTERSPEECH2020) <br /> [Xiao et al., AAAI’21](#ASR-sample-AAAI21)|[Florian et al., ICASSP’21](#lux2021meta)|Learning to optimize: <br /> [Klejch et al., INTERSPEECH’18](#Klejch__COMMA__INTERSPEECH18) <br /> Network architecture search: <br /> [Chen et al., INTERSPEECH’20](#Chen__COMMA__INTERSPEECH20) <br /> [Baruwa et al., IJSER’19](#Baruwa__COMMA__IJSER19)|
|Source Separation|[Kuei et al., ICASSP’21](#SP-ICASSP21)|||
|Keyword Spotting|[Chen et al., INTERSPEECH’20](#Chen__COMMA__arXiv18)||Network architecture search: <br /> [Mazzawi et al., INTERSPEECH’19](#Mazzawi__COMMA__INTERSPEECH19)|
|Sound Event Detection||[Shimada et al., ICASSP’20](#Shimada__COMMA__arXiv19) <br /> [Chou et al., ICASSP’19](#Chou__COMMA__ICASSP19)||
|Voice Cloning|||Learning the learning algorithm: <br /> [Chen et al., ICLR’19](#Chen__COMMA__ICLR19) <br /> [Serrà et al., NeurIPS’19](#Serra__COMMA__NeurIPS19)|
|||||
|Multi-tasks|||Learning to select data: <br /> [Ishan et al., EACL’21](#tarunesh2021meta)|
|Multi-modal||[Eloff et al., ICASSP’19](#Eloff__COMMA__ICASSP19)|Learning the learning algorithm: <br /> [Surís et al., arXiv’19](#Suris__COMMA__arXiv19) <br /> [Xu et al., Proceedings of the First Workshop on Meta Learning and Its Applications to Natural Language Processing’21](#learningToLearn__COMMA__metaNLP21)|

- <span id=Dou__COMMA__EMNLP19>[Dou et al., EMNLP’19] Zi-Yi Dou and Keyi Yu and Antonios Anastasopoulos, Investigating Meta-Learning Algorithms for Low-Resource Natural Language Understanding Tasks, EMNLP, 2019</span>
- <span id=Bansal__COMMA__arXiv19>[Bansal et al., arXiv’19] Trapit Bansal and Rishikesh Jha and Andrew McCallum, Learning to Few-Shot Learn Across Diverse Natural Language Classification Tasks, arXiv, 2019</span>
- <span id=holla-etal-2020-learning>[Nithin et al., Findings of EMNLP’20] Holla, Nithin and Mishra, Pushkar and Yannakoudakis, Helen and Shutova, Ekaterina, Learning to Learn to Disambiguate: {M}eta-Learning for Few-Shot Word Sense Disambiguation, Findings of EMNLP, 2020</span>
- <span id=MetaKD-arXiv21>[Zhou et al., arXiv’21] Wangchunshu Zhou and Canwen Xu and Julian McAuley, Meta Learning for Knowledge Distillation, arXiv, 2021</span>
- <span id=van-der-heijden-etal-2021-multilingual>[Niels et al., EACL’21] van der Heijden, Niels and Yannakoudakis, Helen and Mishra, Pushkar and Shutova, Ekaterina, Multilingual and cross-lingual document classification: A meta-learning approach, EACL, 2021</span>
- <span id=bansal-etal-2020-self>[Trapit et al., EMNLP’20] Bansal, Trapit and Jha, Rishikesh and Munkhdalai, Tsendsuren and McCallum, Andrew, Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks, EMNLP, 2020</span>
- <span id=murty-etal-2021-dreca>[Shikhar et al., NAACL’21] Murty, Shikhar and Hashimoto, Tatsunori B. and Manning, Christopher, {DR}e{C}a: A General Task Augmentation Strategy for Few-Shot Natural Language Inference, NAACL, 2021</span>
- <span id=Yu__COMMA__ACL18>[Yu et al., ACL’18] Mo Yu and Xiaoxiao Guo and Jinfeng Yi and Shiyu Chang and Saloni Potdar and Yu Cheng and Gerald Tesauro and Haoyu Wang and Bowen Zhou, Diverse Few-Shot Text Classification with Multiple Metrics, ACL, 2018</span>
- <span id=Tan__COMMA__EMNLP19>[Tan et al., EMNLP’19] Ming Tan and Yang Yu and Haoyu Wang and Dakuo Wang and Saloni Potdar and Shiyu Chang and Mo Yu, Out-of-Domain Detection for Low-Resource Text Classification Tasks, EMNLP, 2019</span>
- <span id=Geng__COMMA__EMNLP19>[Geng et al., EMNLP’19] Ruiying Geng and Binhua Li and Yongbin Li and Xiaodan Zhu and Ping Jian and Jian Sun, Induction Networks for Few-Shot Text Classification, EMNLP, 2019</span>
- <span id=Sun__COMMA__EMNLP19>[Sun et al., EMNLP’19] Shengli Sun and Qingfeng Sun and Kevin Zhou and Tengchao Lv, Hierarchical Attention Prototypical Networks for Few-Shot Text Classification, EMNLP, 2019</span>
- <span id=geng2020dynamic>[Ruiying et al., ACL’20] Geng, Ruiying and Li, Binhua and Li, Yongbin and Sun, Jian and Zhu, Xiaodan, Dynamic Memory Induction Networks for Few-Shot Text Classification, ACL, 2020</span>
- <span id=Wu__COMMA__EMNLP19>[Wu et al., EMNLP’19] Jiawei Wu and Wenhan Xiong and William Yang Wang, Learning to Learn and Predict: A Meta-Learning Approach for Multi-Label Classification, EMNLP, 2019</span>
- <span id=pasunuru2020fenas>[Ramakanth et al., EMNLP’20] Pasunuru, Ramakanth and Bansal, Mohit, FENAS: Flexible and Expressive Neural Architecture Search, EMNLP, 2020</span>
- <span id=pasunuru2019continual>[Ramakanth et al., ACL’19] Pasunuru, Ramakanth and Bansal, Mohit, Continual and Multi-Task Architecture Search, ACL, 2019</span>
- <span id=learningToOptimize__COMMA__metaNLP21>[Xu et al., Proceedings of the First Workshop on Meta Learning and Its Applications to Natural Language Processing’21] Weijia Xu and Batool Haider and Jason Krone and Saab Mansour, Soft Layer Selection with Meta-Learning for Zero-Shot Cross-Lingual Transfer, Proceedings of the First Workshop on Meta Learning and Its Applications to Natural Language Processing, 2021</span>
- <span id=label-correction-aaai21>[Zheng et al., AAAI’21] Guoqing Zheng and Ahmed H. Awadallah and Susan Dumais, Meta Label Correction for Noisy Label Learning, AAAI, 2021</span>
- <span id=Wu__COMMA__AAAI20>[Wu et al., AAAI’20] Qianhui Wu and Zijia Lin and Guoxin Wang and Hui Chen and Börje F. Karlsson and Biqing Huang and Chin-Yew Lin, Enhanced Meta-Learning for Cross-lingual Named Entity Recognition with Minimal Resources, AAAI, 2020</span>
- <span id=xia-etal-2021-metaxl>[Mengzhou et al., NAACL’21] Xia, Mengzhou and Zheng, Guoqing and Mukherjee, Subhabrata and Shokouhi, Milad and Neubig, Graham and Awadallah, Ahmed Hassan, {M}eta{XL}: Meta Representation Transformation for Low-resource Cross-lingual Learning, NAACL, 2021</span>
- <span id=Hou__COMMA__ACL20>[Hou et al., ACL’20] Yutai Hou and Wanxiang Che and Yongkui Lai and Zhihan Zhou and Yijia Liu and Han Liu and Ting Liu, Few-shot Slot Tagging with Collapsed Dependency Transfer and Label-enhanced Task-adaptive Projection Network, ACL, 2020</span>
- <span id=yang2020frustratingly>[Yi et al., EMNLP’20] Yang, Yi and Katiyar, Arzoo, Frustratingly Simple Few-Shot Named Entity Recognition with Structured Nearest Neighbor Learning, EMNLP, 2020</span>
- <span id=oguz2021few>[Cennet et al., EACL’21] Oguz, Cennet and Vu, Ngoc Thang, Few-shot Learning for Slot Tagging with Attentive Relational Network, EACL, 2021</span>
- <span id=li2020learning>[Yinqiao et al., ACL’20] Li, Yinqiao and Hu, Chi and Zhang, Yuhao and Xu, Nuo and Jiang, Yufan and Xiao, Tong and Zhu, Jingbo and Liu, Tongran and Li, Changliang, Learning Architectures from an Extended Search Space for Language Modeling, ACL, 2020</span>
- <span id=jiang2019improved>[Yufan et al., EMNLP’19] Jiang, Yufan and Hu, Chi and Xiao, Tong and Zhang, Chunliang and Zhu, Jingbo, Improved differentiable architecture search for language modeling and named entity recognition, EMNLP, 2019</span>
- <span id=Obamuyide__COMMA__ACL19>[Obamuyide et al., ACL’19] Abiola Obamuyide and Andreas Vlachos, Model-Agnostic Meta-Learning for Relation Classification with Limited Supervision, ACL, 2019</span>
- <span id=Bose__COMMA__arXiv19>[Bose et al., arXiv’19] Avishek Joey Bose and Ankit Jain and Piero Molino and William L. Hamilton, Meta-Graph:Few shot Link Prediction via Meta Learning, arXiv, 2019</span>
- <span id=Lv__COMMA__EMNLP19>[Lv et al., EMNLP’19] Xin Lv and Yuxian Gu and Xu Han and Lei Hou and Juanzi Li and Zhiyuan Liu, Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over Few-Shot Relations, EMNLP, 2019</span>
- <span id=Ye__COMMA__ACL19>[Ye et al., ACL’19] Zhi-Xiu Ye and Zhen-Hua Ling, Multi-Level Matching and Aggregation Network for Few-Shot Relation Classification, ACL, 2019</span>
- <span id=Chen__COMMA__EMNLP19>[Chen et al., EMNLP’19] Mingyang Chen and Wen Zhang and Wei Zhang and Qiang Chen and Huajun Chen, Meta Relational Learning for Few-Shot Link Prediction in Knowledge Graphs, EMNLP, 2019</span>
- <span id=Xiong__COMMA__EMNLP18>[Xiong et al., EMNLP’18] Wenhan Xiong and Mo Yu and Shiyu Chang and Xiaoxiao Guo and William Yang Wang, One-Shot Relational Learning for Knowledge Graphs, EMNLP, 2018</span>
- <span id=Gao__COMMA__AAAI19>[Gao et al., AAAI’19] Tianyu Gao and Xu Han and Zhiyuan Liu and Maosong Sun, Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification, AAAI, 2019</span>
- <span id=ren2020two>[Haopeng et al., Proceedings of the 28th International Conference on Computational Linguistics’20] Ren, Haopeng and Cai, Yi and Chen, Xiaofeng and Wang, Guohua and Li, Qing, A Two-phase Prototypical Network Model for Incremental Few-shot Relation Classification, Proceedings of the 28th International Conference on Computational Linguistics, 2020</span>
- <span id=xiong2018one>[Wenhan et al., EMNLP’18] Xiong, Wenhan and Yu, Mo and Chang, Shiyu and Guo, Xiaoxiao and Wang, William Yang, One-Shot Relational Learning for Knowledge Graphs, EMNLP, 2018</span>
- <span id=wang2019tackling>[Zihao et al., EMNLP-IJCNLP’19] Wang, Zihao and Lai, Kwunping and Li, Piji and Bing, Lidong and Lam, Wai, Tackling Long-Tailed Relations and Uncommon Entities in Knowledge Graph Completion, EMNLP-IJCNLP, 2019</span>
- <span id=zhang2020few>[Chuxu et al., AAAI’20] Zhang, Chuxu and Yao, Huaxiu and Huang, Chao and Jiang, Meng and Li, Zhenhui and Chawla, Nitesh V, Few-shot knowledge graph completion, AAAI, 2020</span>
- <span id=sheng2020adaptive>[Jiawei et al., EMNLP’20] Sheng, Jiawei and Guo, Shu and Chen, Zhenyu and Yue, Juwei and Wang, Lihong and Liu, Tingwen and Xu, Hongbo, Adaptive Attentional Network for Few-Shot Knowledge Graph Completion, EMNLP, 2020</span>
- <span id=Hu__COMMA__ACL19>[Hu et al., ACL’19] Ziniu Hu and Ting Chen and Kai-Wei Chang and Yizhou Sun, Few-Shot Representation Learning for Out-Of-Vocabulary Words, ACL, 2019</span>
- <span id=Sun__COMMA__EMNLP18>[Sun et al., EMNLP’18] Jingyuan Sun and Shaonan Wang and Chengqing Zong, Memory, Show the Way:Memory Based Few Shot Word Representation Learning, EMNLP, 2018</span>
- <span id=li2020learning>[Yinqiao et al., ACL’20] Li, Yinqiao and Hu, Chi and Zhang, Yuhao and Xu, Nuo and Jiang, Yufan and Xiao, Tong and Zhu, Jingbo and Liu, Tongran and Li, Changliang, Learning Architectures from an Extended Search Space for Language Modeling, ACL, 2020</span>
- <span id=jiang2019improved>[Yufan et al., EMNLP’19] Jiang, Yufan and Hu, Chi and Xiao, Tong and Zhang, Chunliang and Zhu, Jingbo, Improved differentiable architecture search for language modeling and named entity recognition, EMNLP, 2019</span>
- <span id=mhamdi-etal-2021-x>[Meryem et al., NAACL’21] M{'}hamdi, Meryem and Kim, Doo Soon and Dernoncourt, Franck and Bui, Trung and Ren, Xiang and May, Jonathan, {X}-{METRA}-{ADA}: Cross-lingual Meta-Transfer learning Adaptation to Natural Language Understanding and Question Answering, NAACL, 2021</span>
- <span id=nooralahzadeh-etal-2020-zero>[Farhad et al., EMNLP’20] Nooralahzadeh, Farhad and Bekoulis, Giannis and Bjerva, Johannes and Augenstein, Isabelle, Zero-Shot Cross-Lingual Transfer with Meta Learning, EMNLP, 2020</span>
- <span id=yan-etal-2020-multi-source>[Ming et al., ACL’20] Yan, Ming and Zhang, Hao and Jin, Di and Zhou, Joey Tianyi, Multi-source Meta Transfer for Low Resource Multiple-Choice Question Answering, ACL, 2020</span>
- <span id=hua-etal-2020-shot>[Yuncheng et al., EMNLP’20] Hua, Yuncheng and Li, Yuan-Fang and Haffari, Gholamreza and Qi, Guilin and Wu, Tongtong, Few-Shot Complex Knowledge Base Question Answering via Meta Reinforcement Learning, EMNLP, 2020</span>
- <span id=Gu__COMMA__EMNLP18>[Gu et al., EMNLP’18] Jiatao Gu and Yong Wang and Yun Chen and Kyunghyun Cho and Victor O.K. Li, Meta-Learning for Low-Resource Neural Machine Translation, EMNLP, 2018</span>
- <span id=Indurthi__COMMA__arXiv19>[Indurthi et al., ICASSP’20] Sathish Indurthi and Houjeung Han and Nikhil Kumar Lakumarapu and Beomseok Lee and Insoo Chung and Sangha Kim and Chanwoo Kim, Data Efficient Direct Speech-to-Text Translation with Modality Agnostic Meta-Learning, ICASSP, 2020</span>
- <span id=Li_Wang_Yu_2020>[Rumeng et al., AAAI’20] Li, Rumeng and Wang, Xun and Yu, Hong, MetaMT, a Meta Learning Method Leveraging Multiple Domain Data for Low Resource Machine Translation, AAAI, 2020</span>
- <span id=unsupervisedMT-acl21>[Park et al., ACL’21] Cheonbok Park and Yunwon Tae and Taehee Kim and Soyoung Yang and Mohammad Azam Khan and Eunjeong Park and Jaegul Choo, Unsupervised Neural Machine Translation for Low-Resource Domains via Meta-Learning, ACL, 2021</span>
- <span id=wang2020hat>[Hanrui et al., ACL’20] Wang, Hanrui and Wu, Zhanghao and Liu, Zhijian and Cai, Han and Zhu, Ligeng and Gan, Chuang and Han, Song, HAT: Hardware-Aware Transformers for Efficient Natural Language Processing, ACL, 2020</span>
- <span id=wang2020balancing>[Xinyi et al., ACL’20] Wang, Xinyi and Tsvetkov, Yulia and Neubig, Graham, Balancing Training for Multilingual Neural Machine Translation, ACL, 2020</span>
- <span id=pham2020meta>[Hieu et al., ICLR’21] Pham, Hieu and Wang, Xinyi and Yang, Yiming and Neubig, Graham, Meta Back-Translation, ICLR, 2021</span>
- <span id=Guo__COMMA__ACL19>[Guo et al., ACL’19] Daya Guo and Duyu Tang and Nan Duan and Ming Zhou and Jian Yin, Coupling Retrieval and Meta-Learning for Context-Dependent Semantic Parsing, ACL, 2019</span>
- <span id=Huang__COMMA__NAACL18>[Huang et al., NAACL’18] Po-Sen Huang and Chenglong Wang and Rishabh Singh and Wen-tau Yih and Xiaodong He, Natural Language to Structured Query Generation via Meta-Learning, NAACL, 2018</span>
- <span id=multiparsing>[Langedijk et al., arXiv’21] Anna Langedijk and Verna Dankers and Phillip Lippe and Sander Bos and Bryan Cardenas Guevara and Helen Yannakoudakis and Ekaterina Shutova, Meta-learning for fast cross-lingual adaptation in dependency parsing, arXiv, 2021</span>
- <span id=chen-etal-2020-low>[Xilun et al., EMNLP’20] Chen, Xilun and Ghoshal, Asish and Mehdad, Yashar and Zettlemoyer, Luke and Gupta, Sonal, Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing, EMNLP, 2020</span>
- <span id=wang-etal-2021-meta>[Bailin et al., NAACL’21] Wang, Bailin and Lapata, Mirella and Titov, Ivan, Meta-Learning for Domain Generalization in Semantic Parsing, NAACL, 2021</span>
- <span id=Qian__COMMA__ACL19>[Qian et al., ACL’19] Kun Qian and Zhou Yu, Domain Adaptive Dialog Generation via Meta Learning, ACL, 2019</span>
- <span id=Madotto__COMMA__ACL19>[Madotto et al., ACL’19] Andrea Madotto and Zhaojiang Lin and Chien-Sheng Wu and Pascale Fung, Personalizing Dialogue Agents via Meta-Learning, ACL, 2019</span>
- <span id=Mi__COMMA__IJCAI19>[Mi et al., IJCAI’19] Fei Mi and Minlie Huang and Jiyong Zhang and Boi Faltings, Meta-Learning for Low-resource Natural Language Generation in Task-oriented Dialogue Systems, IJCAI, 2019</span>
- <span id=Huang__COMMA__ACL20>[Huang et al., ACL’20] Yi Huang and Junlan Feng and Min Hu and Xiaoting Wu and Xiaoyu Du and Shuo Ma, Meta-Reinforced Multi-Domain State Generator for Dialogue Systems, ACL, 2020</span>
- <span id=dingliwal-etal-2021-shot>[Saket et al., EACL’21] Dingliwal, Saket and Gao, Shuyang and Agarwal, Sanchit and Lin, Chien-Wei and Chung, Tagyoung and Hakkani-Tur, Dilek, Few Shot Dialogue State Tracking using Meta-learning, EACL, 2021</span>
- <span id=ST-dialogue-AAAI21>[Qian et al., AAAI’21] Kun Qian and Wei Wei and Zhou Yu, A Student-Teacher Architecture for Dialog Domain Adaptation under the Meta-Learning Setting, AAAI, 2021</span>
- <span id=dai-etal-2020-learning>[Yinpei et al., ACL’20] Dai, Yinpei and Li, Hangyu and Tang, Chengguang and Li, Yongbin and Sun, Jian and Zhu, Xiaodan, Learning Low-Resource End-To-End Goal-Oriented Dialog for Fast and Reliable System Deployment, ACL, 2020</span>
- <span id=huang-etal-2020-towards-low>[Yi et al., Findings of EMNLP’20] Huang, Yi and Feng, Junlan and Ma, Shuo and Du, Xiaoyu and Wu, Xiaoting, Towards Low-Resource Semi-Supervised Dialogue Generation with Meta-Learning, Findings of EMNLP, 2020</span>
- <span id=Chien__COMMA__INTERSPEECH19>[Chien et al., INTERSPEECH’19] Jen-Tzung Chien and Wei Xiang Lieow, Meta Learning for Hyperparameter Optimization in Dialogue System, INTERSPEECH, 2019</span>
- <span id=Hsu__COMMA__ICASSP20>[Hsu et al., ICASSP’20] Jui-Yang Hsu and Yuan-Jui Chen and Hung-yi Lee, Meta Learning for End-to-End Low-Resource Speech Recognition, ICASSP, 2020</span>
- <span id=Klejch__COMMA__ASRU19>[Klejch et al., ASRU’19] Ondřej Klejch and Joachim Fainberg and Peter Bell and Steve Renals, Speaker Adaptive Training using Model Agnostic Meta-Learning, ASRU, 2019</span>
- <span id=Winata__COMMA__ACL2020>[Winata et al., ACL’20] Genta Indra Winata and Samuel Cahyawijaya and Zhaojiang Lin and Zihan Liu and Peng Xu and Pascale Fung, Meta-Transfer Learning for Code-Switched Speech Recognition, ACL, 2020</span>
- <span id=Winata__COMMA__INTERSPEECH2020>[Winata et al., INTERSPEECH’20] Genta Indra Winata and Samuel Cahyawijaya and Zihan Liu and Zhaojiang Lin and Andrea Madotto and Peng Xu and Pascale Fung, Learning Fast Adaptation on Cross-Accented Speech Recognition, INTERSPEECH, 2020</span>
- <span id=ASR-sample-AAAI21>[Xiao et al., AAAI’21] Yubei Xiao and Ke Gong and Pan Zhou and Guolin Zheng and Xiaodan Liang and Liang Lin, Adversarial Meta Sampling for Multilingual Low-Resource Speech Recognition, AAAI, 2021</span>
- <span id=lux2021meta>[Florian et al., ICASSP’21] Lux, Florian and Vu, Ngoc Thang, Meta-Learning for improving rare word recognition in end-to-end ASR, ICASSP, 2021</span>
- <span id=Klejch__COMMA__INTERSPEECH18>[Klejch et al., INTERSPEECH’18] Ondřej Klejch and Joachim Fainberg and Peter Bell, Learning to adapt:a meta-learning approach for speaker adaptation, INTERSPEECH, 2018</span>
- <span id=Chen__COMMA__INTERSPEECH20>[Chen et al., INTERSPEECH’20] Yi-Chen Chen and Jui-Yang Hsu and Cheng-Kuang Lee and Hung-yi Lee, {DARTS}-{ASR}: Differentiable Architecture Search for Multilingual Speech Recognition and Adaptation, INTERSPEECH, 2020</span>
- <span id=Baruwa__COMMA__IJSER19>[Baruwa et al., IJSER’19] Ahmed Baruwa and Mojeed Abisiga and Ibrahim Gbadegesin and Afeez Fakunle, Leveraging End-to-End Speech Recognition with Neural Architecture Search, IJSER, 2019</span>
- <span id=SP-ICASSP21>[Kuei et al., ICASSP’21] Wu, Yuan-Kuei and Huang, Kuan-Po and Tsao, Yu and Lee, Hung-yi, One Shot Learning for Speech Separation, ICASSP, 2021</span>
- <span id=Chen__COMMA__arXiv18>[Chen et al., INTERSPEECH’20] Yangbin Chen and Tom Ko and Lifeng Shang and Xiao Chen and Xin Jiang and Qing Li, An Investigation of Few-Shot Learning in Spoken Term Classification, INTERSPEECH, 2020</span>
- <span id=Mazzawi__COMMA__INTERSPEECH19>[Mazzawi et al., INTERSPEECH’19] Hanna Mazzawi and Xavi Gonzalvo and Aleks Kracun and Prashant Sridhar and Niranjan Subrahmanya and Ignacio Lopez Moreno and Hyun Jin Park and Patrick Violette, Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale, INTERSPEECH, 2019</span>
- <span id=Shimada__COMMA__arXiv19>[Shimada et al., ICASSP’20] Kazuki Shimada and Yuichiro Koyama and Akira Inoue, Metric Learning with Background Noise Class for Few-shot Detection of Rare Sound Events, ICASSP, 2020</span>
- <span id=Chou__COMMA__ICASSP19>[Chou et al., ICASSP’19] Szu-Yu Chou and Kai-Hsiang Cheng and Jyh-Shing Roger Jang and Yi-Hsuan Yang, Learning to match transient sound events using attentional similarity for few-shot sound recognition, ICASSP, 2019</span>
- <span id=Chen__COMMA__ICLR19>[Chen et al., ICLR’19] Yutian Chen and Yannis Assael and Brendan Shillingford and David Budden and Scott Reed and Heiga Zen and Quan Wang and Luis C. Cobo and Andrew Trask and Ben Laurie and Caglar Gulcehre and Aäron van den Oord and Oriol Vinyals and Nando de Freitas, Sample Efficient Adaptive Text-to-Speech, ICLR, 2019</span>
- <span id=Serra__COMMA__NeurIPS19>[Serrà et al., NeurIPS’19] Joan Serrà and Santiago Pascual and Carlos Segura, Blow:a single-scale hyperconditioned flow for non-parallel raw-audio voice conversion, NeurIPS, 2019</span>
- <span id=tarunesh2021meta>[Ishan et al., EACL’21] Tarunesh, Ishan and Khyalia, Sushil and Kumar, Vishwajeet and Ramakrishnan, Ganesh and Jyothi, Preethi, Meta-Learning for Effective Multi-task and Multilingual Modelling, EACL, 2021</span>
- <span id=Eloff__COMMA__ICASSP19>[Eloff et al., ICASSP’19] Ryan Eloff and Herman A. Engelbrecht and Herman Kamper, MULTIMODAL ONE-SHOT LEARNING OF SPEECH AND IMAGES, ICASSP, 2019</span>
- <span id=Suris__COMMA__arXiv19>[Surís et al., arXiv’19] Dídac Surís and Dave Epstein and Heng Ji and Shih-Fu Chang and Carl Vondrick, Learning to Learn Words from Narrated Video, arXiv, 2019</span>
- <span id=learningToLearn__COMMA__metaNLP21>[Xu et al., Proceedings of the First Workshop on Meta Learning and Its Applications to Natural Language Processing’21] Guangyue Xu and Parisa Kordjamshidi and Joyce Chai, Zero-Shot Compositional Concept Learning, Proceedings of the First Workshop on Meta Learning and Its Applications to Natural Language Processing, 2021</span>
